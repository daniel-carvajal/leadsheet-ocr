{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Necessary imports"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "f3b135aa-00e3-4dd0-8293-53e94b2b5d39"
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.lib.pretty import pretty\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1678492905189
        },
        "tags": []
      },
      "id": "de4ad180-540c-4cf4-9896-cc12fe573b34"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torch\n",
        "%pip install torchvision"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: torch in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (1.13.1)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (11.10.3.66)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (11.7.99)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (11.7.99)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (8.5.0.96)\nRequirement already satisfied: typing-extensions in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch) (4.4.0)\nRequirement already satisfied: setuptools in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (61.2.0)\nRequirement already satisfied: wheel in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: torchvision in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (0.14.1)\nRequirement already satisfied: requests in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torchvision) (2.28.2)\nRequirement already satisfied: numpy in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torchvision) (1.23.5)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torchvision) (9.4.0)\nRequirement already satisfied: typing-extensions in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torchvision) (4.4.0)\nRequirement already satisfied: torch==1.13.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torchvision) (1.13.1)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch==1.13.1->torchvision) (11.7.99)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch==1.13.1->torchvision) (11.10.3.66)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch==1.13.1->torchvision) (11.7.99)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from torch==1.13.1->torchvision) (8.5.0.96)\nRequirement already satisfied: wheel in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision) (0.37.1)\nRequirement already satisfied: setuptools in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision) (61.2.0)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests->torchvision) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests->torchvision) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests->torchvision) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests->torchvision) (1.26.14)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      },
      "id": "285dcf5a-5b22-443f-b206-3419a62b9457"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "0e91888d-0731-4317-833e-0eba9dfa7823"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define helper functions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      },
      "id": "3e27448f-b01e-4319-a644-fdd8a118fbdb"
    },
    {
      "cell_type": "code",
      "source": [
        "def listToString(array):\n",
        "    return (\"[\" + \", \".join(f\"'{str(i)}'\" for i in array) + \"]\")\n",
        "\n",
        "def stringToList(s):\n",
        "    return list(map(int, s.strip('[]').split(',')))"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1678492910923
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      },
      "id": "ced4210c-90fe-4e9c-a5cb-c535d2d91123"
    },
    {
      "cell_type": "code",
      "source": [
        "def checkIfDominant(string):\n",
        "    return string[1] == '7' or string[1] == '9' or string[1:3] == '13' or string[1:3] == '67'\n",
        "\n",
        "def getDominantType(string):\n",
        "        if string[1:3] == '13':\n",
        "            return \"13\"\n",
        "        if string[1:3] == '11':\n",
        "            return \"11\"\n",
        "        if string[1] == '9':\n",
        "            return \"9\"\n",
        "        if string[1] == '7':\n",
        "            return \"7\"\n",
        "        # if string[1:3] == '67':\n",
        "        #     return '6'\n",
        "        if string[1:3] == '67':\n",
        "            return '67'\n",
        "\n",
        "\n",
        "def getChordType(chord_noAcc, major, minor, diminished, dominant, dominant_type):\n",
        "\n",
        "    if minor or diminished:\n",
        "        if chord_noAcc[2] == \"7\":\n",
        "            return \"min7\"\n",
        "        elif chord_noAcc[2] == \"9\" or chord_noAcc[2] == \"6\": \n",
        "            return 'min' + chord_noAcc[2]\n",
        "        elif chord_noAcc[2] == \"1\": \n",
        "            return 'min' + chord_noAcc[2:4]\n",
        "        else:\n",
        "            return \"min5\"\n",
        "\n",
        "    if major:\n",
        "        if chord_noAcc[4:6] == \"67\":\n",
        "            return \"maj67\"\n",
        "        if chord_noAcc[4] == \"7\":\n",
        "            return \"maj7\"\n",
        "        if chord_noAcc[4] == \"9\": \n",
        "            return 'maj9'\n",
        "        # if chord_noAcc[4] == \"6\": ## Notation like C6 is used without maj.\n",
        "            # return \"maj6\"\n",
        "        elif chord_noAcc[4] == \"1\": \n",
        "            return 'maj' + chord_noAcc[4:6]\n",
        "\n",
        "    if dominant:\n",
        "        # print(dominant)\n",
        "        return 'dominant' + dominant_type\n",
        "\n",
        "    if not dominant and not major and not minor and not diminished:\n",
        "        try:\n",
        "            if chord_noAcc[1:4] == \"aug\":\n",
        "                return \"aug\"\n",
        "            if chord_noAcc[1:3] == \"69\":\n",
        "                return \"69\"\n",
        "            elif chord_noAcc[1] == \"6\":\n",
        "                return \"6\"\n",
        "            else:\n",
        "                return \"maj5\"\n",
        "                # return \"uncertain\"\n",
        "        except IndexError:\n",
        "            print('ERROR!')\n",
        "\n",
        "\n",
        "def getAddDegree(chord):\n",
        "    add_accidental = \"N/A\"\n",
        "    add_idx = None\n",
        "    addNote_degree = \"N/A\"\n",
        "\n",
        "    add_idx = chord.find('add')\n",
        "\n",
        "    if chord[add_idx+3] == 'â™­' or chord[add_idx+3] == '#':    ## Accidental found in add!\n",
        "        add_accidental = chord[add_idx+3]\n",
        "\n",
        "    if add_accidental == \"N/A\":\n",
        "        if chord[add_idx+3] == \"9\":\n",
        "            addNote_degree = \"9\"\n",
        "        if chord[add_idx+3] == \"6\":\n",
        "            addNote_degree = \"6\"\n",
        "        if chord[add_idx+3] == \"4\":\n",
        "            addNote_degree = \"4\"\n",
        "        elif chord[add_idx+3] == \"1\":\n",
        "            addNote_degree = chord[add_idx+3:chord[add_idx+4]]\n",
        "\n",
        "    if add_accidental != \"N/A\":\n",
        "        chord_addAccRemoved = chord[:add_idx+3] + chord[add_idx+4:]\n",
        "        if chord_addAccRemoved[add_idx+3] == \"9\":\n",
        "            addNote_degree =  \"9\"\n",
        "        if chord_addAccRemoved[add_idx+3] == \"6\":\n",
        "            addNote_degree = \"6\"\n",
        "        elif chord_addAccRemoved[add_idx+3] == \"1\":\n",
        "            addNote_degree = chord_addAccRemoved[add_idx+3:add_idx+5]\n",
        "\n",
        "    return addNote_degree, add_accidental"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1678492911136
        },
        "tags": []
      },
      "id": "e5405bf1-935c-4731-97fd-5d56e16299ac"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_subdescriptor_dict(chord):\n",
        "    root = chord[0]\n",
        "    root_accidental = \"â™®\"\n",
        "    chord_noAcc = chord\n",
        "\n",
        "    if chord[1] == \"â™­\" or chord[1] == \"#\":\n",
        "        root_accidental = chord[1]\n",
        "        chord_noAcc = chord_noAcc[0:1] + chord_noAcc[2:]     ## Remove accidental for easier parsing\n",
        "\n",
        "    dominant = checkIfDominant(chord_noAcc)\n",
        "    dominant_type = \"N/A\" \n",
        "    \n",
        "    if dominant:\n",
        "        dominant_type = getDominantType(chord_noAcc)\n",
        "\n",
        "    diminished = chord_noAcc[1] == 'o'\n",
        "    minor = chord_noAcc[1] == 'm'\n",
        "\n",
        "    major = 'Maj' in chord_noAcc[1:4] \n",
        "    sus4 = 'sus4' in chord_noAcc\n",
        "\n",
        "    slash_note = 'N/A'\n",
        "    alteration = []\n",
        "    matches = []\n",
        "\n",
        "    ## Check for '(â™­5)' in  Fm9(â™­5)\n",
        "    if '/' in chord:\n",
        "        index = chord.find('/')\n",
        "        slash_note = chord[index+1:]\n",
        "\n",
        "    if '(' in chord:\n",
        "        start_index = chord.find('(')\n",
        "        end_index = chord.find(')')\n",
        "\n",
        "        alteration = chord[start_index+1:end_index]       \n",
        "        pattern = \"([â™­#]\\d+)\"\n",
        "        matches =  re.findall(pattern, alteration)        \n",
        "\n",
        "    add_present = 'add' in chord or 'Î”' in chord\n",
        "    add_accidental = \"N/A\"\n",
        "    addNote_degree = \"N/A\"\n",
        "\n",
        "    if add_present:\n",
        "        add_idx = chord.find('add')\n",
        "        addNote_degree, add_accidental = getAddDegree(chord)\n",
        "\n",
        "    chord_type = \"\"\n",
        "    chord_type = getChordType(chord_noAcc, major, minor, diminished, dominant, dominant_type)\n",
        "\n",
        "\n",
        "    return {\n",
        "            'root': root,\n",
        "            'root_accidental': root_accidental,\n",
        "            'chord_type': chord_type,\n",
        "            'slash_note': slash_note,\n",
        "            'alternations': matches,\n",
        "            'diminished_substring': diminished,\n",
        "            'major_substring': major,\n",
        "            'minor_substring': minor,\n",
        "            'dominant': dominant,\n",
        "            'dominant_type': dominant_type,\n",
        "            'sus4_substring': sus4,\n",
        "            'addNote_accidental': add_accidental,\n",
        "            'addNote_degree': addNote_degree,\n",
        "        }\n",
        "    "
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1678492911322
        },
        "jupyter": {
          "source_hidden": false
        },
        "tags": []
      },
      "id": "c085c1e9-8a1c-4b30-b607-51c6f4a8756b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "tags": []
      },
      "id": "d4f0549e-155d-4bd1-8597-e48e31c51790"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Collect dataset images into a dictionary"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "5dad3310-a6fe-41b9-a38d-d868dd687632"
    },
    {
      "cell_type": "code",
      "source": [
        "def filepathToChord(filename):\n",
        "    if not filename.endswith(\".png\"):\n",
        "        return None\n",
        "    parts = filename.split(\"_\")\n",
        "    label = parts[-2]  \n",
        "    return label\n"
      ],
      "outputs": [],
      "execution_count": 52,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1678495718732
        }
      },
      "id": "0e5568e2-1401-4010-80d2-ab0a5f385231"
    },
    {
      "cell_type": "code",
      "source": [
        "# %%script echo skipping\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "data_dir = \"../output\"\n",
        "\n",
        "labels = []\n",
        "\n",
        "dataset = {}\n",
        "for filename in os.listdir(data_dir):\n",
        "    if not filename.endswith(\".png\"):\n",
        "        continue\n",
        "    parts = filename.split(\"_\")\n",
        "    label = parts[-2]                   # Extract the second-to-last part as the label\n",
        "    # print(label)\n",
        "    labels.append(label)\n",
        "    img_path = os.path.join(data_dir, filename)\n",
        "    dataset[img_path] = label"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1678492911518
        },
        "tags": []
      },
      "id": "d2cb357e-bf23-488c-b5fd-013b5561bf3e"
    },
    {
      "cell_type": "code",
      "source": [
        "# print(dataset)\n",
        "print(len(dataset.items()))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "502\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1678492911710
        },
        "tags": []
      },
      "id": "f36a9ef0-7b6a-4633-b839-f5ed08792224"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define possible_subdescriptors_dict"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      },
      "id": "a2010f45-e368-4c9b-baa7-eb58ae9a1aa7"
    },
    {
      "cell_type": "code",
      "source": [
        "possible_subdescriptors_dict = {\n",
        "  \"root\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"],\n",
        "  \"root_accidental\": [\"â™®\", \"#\", \"â™­\"],\n",
        "  \"chord_type\": [\n",
        "    \"maj5\",\n",
        "    \"maj67\",\n",
        "    \"maj7\",\n",
        "    \"maj9\",\n",
        "    \"maj#11\",\n",
        "    \"maj13\",\n",
        "    \"6\",\n",
        "    \"69\",\n",
        "    \"dominant6\",\n",
        "    \"dominant67\",\n",
        "    \"dominant7\",\n",
        "    \"dominant9\",\n",
        "    \"dominant13\",\n",
        "    \"min5\",\n",
        "    \"min6\",\n",
        "    \"min7\",\n",
        "    \"min9\",\n",
        "    \"min11\",\n",
        "    \"min13\",\n",
        "    \"aug\"\n",
        "  ],\n",
        "  \"slash_note\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"N/A\"],\n",
        "  \"alternations\": [\n",
        "    \"['â™­5']\",\n",
        "    \"['â™­5', '#9']\",\n",
        "    \"['#5']\",\n",
        "    \"['#5', '#9']\",\n",
        "    \"['#9']\",\n",
        "    \"['#11']\",\n",
        "    \"['â™­6']\",\n",
        "    \"['â™­9', '#11']\",\n",
        "    \"['â™­9']\",\n",
        "    \"['â™­13']\",\n",
        "    \"[]\"\n",
        "  ],\n",
        "  \"diminished_substring\": [\"False\", \"True\"],\n",
        "  \"major_substring\": [\"False\", \"True\"],\n",
        "  \"minor_substring\": [\"False\", \"True\"],\n",
        "  \"dominant\": [\"False\", \"True\"],\n",
        "  \"dominant_type\": [\"N/A\", \"67\", \"7\", \"9\", \"11\", \"13\"],\n",
        "  \"sus4_substring\": [\"False\", \"True\"],\n",
        "  \"addNote_accidental\": [\"N/A\", \"#\", \"â™­\"],\n",
        "  \"addNote_degree\": [\"N/A\", \"4\", \"6\", \"9\", \"11\"]\n",
        "}\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1678492911898
        },
        "jupyter": {
          "source_hidden": false
        },
        "tags": []
      },
      "id": "97f2e77b-35ec-4e81-ab65-62b7be80edd3"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "value_to_int = {}\n",
        "int_to_value = {}\n",
        "\n",
        "for label in possible_subdescriptors_dict:\n",
        "    label_values = possible_subdescriptors_dict[label]\n",
        "    for i, value in enumerate(label_values):\n",
        "        value_to_int[(label, value)] = i\n",
        "        int_to_value[(label, i)] = value"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1678492912083
        },
        "tags": []
      },
      "id": "68bc1185-f43a-419b-880e-2c8c566af3f1"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_binary_encoding(chord):\n",
        "    chord_sublabels = get_subdescriptor_dict(chord)\n",
        "    label_encoding = {}\n",
        "    binary_encodings_concatenated = []\n",
        "\n",
        "    for  key, val in chord_sublabels.items():\n",
        "\n",
        "        if type(val) == list:\n",
        "            val = listToString(val)\n",
        "        if type(val) == bool:\n",
        "            val = str(val)\n",
        "        \n",
        "        access_tuple = (key, val)\n",
        "        label_encoding[key] = value_to_int[access_tuple]\n",
        "\n",
        "\n",
        "    for chord_label, possibilities in possible_subdescriptors_dict.items(): # Shape => { root:['A', 'B', ..], root_accidental:[..] }\n",
        "        # binary_encoding is the encoding for a each single array of possibilities\n",
        "        binary_encoding = [0] * len(possibilities)\n",
        "        binary_encoding[label_encoding[chord_label]] = 1\n",
        "        binary_encodings_concatenated.extend(binary_encoding)\n",
        "    \n",
        "    return(binary_encodings_concatenated)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1678492912278
        },
        "tags": []
      },
      "id": "d18fa3cd-b44e-4e48-aed6-bfea26559d5a"
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_encoding_to_subdescriptor(binary_encoding):\n",
        "    # print('original binary_encoding', binary_encoding)\n",
        "    subdescriptor_dict = {}\n",
        "    for subdescriptor_name, subdescriptor_values in possible_subdescriptors_dict.items():\n",
        "        \n",
        "        subdescriptor_dict[subdescriptor_name] = subdescriptor_values[binary_encoding[0:len(subdescriptor_values)].argmax().item()]\n",
        "        # print('slided by subdescriptor_name', subdescriptor_name)\n",
        "        # print('slicied by length', len(subdescriptor_values))\n",
        "        binary_encoding = binary_encoding[len(subdescriptor_values):]\n",
        "        # print('sliced into', len(binary_encoding))\n",
        "        # print(binary_encoding[0:len(subdescriptor_values)].argmax().item())\n",
        "        # print('\\n')\n",
        "    return subdescriptor_dict"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1678492912468
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "3f3bce71-942d-48d8-9576-5aedc248f84e"
    },
    {
      "cell_type": "code",
      "source": [
        "# # print(create_binary_encoding(\"CMaj7\"))\n",
        "# c_get_subdescriptor_dict = get_subdescriptor_dict(\"CMaj7\")\n",
        "# print(c_get_subdescriptor_dict)\n"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1678492912651
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      },
      "id": "9ccd28f7-46a7-4f12-bbc4-98f89fc5d03a"
    },
    {
      "cell_type": "code",
      "source": [
        "# # print(create_binary_encoding(\"AMaj7\"))\n",
        "# chord_t = create_binary_encoding(\"E7\")\n",
        "# print('chord_t LENGTH:', len(chord_t))\n",
        "# print(binary_encoding_to_subdescriptor(torch.tensor(chord_t)))\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1678492912838
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      },
      "id": "f43a6b7c-5c2f-497c-869b-650dad730b18"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing: \"create_binary_encoding\" and \"binary_encoding_to_subdescriptor\""
      ],
      "metadata": {},
      "id": "a93f15d9-259a-4100-9349-56781b48e075"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### chord(s) -> (chord_subdescriptors(dict) ->) binary_encoding(t) -> subdescriptor(dict)"
      ],
      "metadata": {},
      "id": "a04ba3f5-df9e-451f-8ae6-4111f2add1b1"
    },
    {
      "cell_type": "code",
      "source": [
        "print(binary_encoding_to_subdescriptor(torch.tensor(create_binary_encoding(\"E7\"))), '\\n')\n",
        "print(binary_encoding_to_subdescriptor(torch.tensor(create_binary_encoding(\"Am9(#5)\"))), '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'root': 'E', 'root_accidental': 'â™®', 'chord_type': 'dominant7', 'slash_note': 'N/A', 'alternations': '[]', 'diminished_substring': 'False', 'major_substring': 'False', 'minor_substring': 'False', 'dominant': 'True', 'dominant_type': '7', 'sus4_substring': 'False', 'addNote_accidental': 'N/A', 'addNote_degree': 'N/A'} \n\n{'root': 'A', 'root_accidental': 'â™®', 'chord_type': 'min9', 'slash_note': 'N/A', 'alternations': \"['#5']\", 'diminished_substring': 'False', 'major_substring': 'False', 'minor_substring': 'True', 'dominant': 'False', 'dominant_type': 'N/A', 'sus4_substring': 'False', 'addNote_accidental': 'N/A', 'addNote_degree': 'N/A'} \n\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1678492913022
        }
      },
      "id": "18c00ad6-65a4-4057-bbd5-2e58b8b13df5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train / Test Split"
      ],
      "metadata": {
        "tags": []
      },
      "id": "fda1138d-5a11-4a83-8629-d076989cf604"
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels_string_list = [*dataset.values()]\n",
        "true_labels_string_list_tuple = [*dataset.items()]"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1678492913206
        }
      },
      "id": "c9629134-43dd-4edb-a3de-7d549cbea381"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define PreparedDataset Class"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "a3665267-a3ad-420d-9123-8bcbeb3f2faf"
    },
    {
      "cell_type": "code",
      "source": [
        "class PreparedDataset(Dataset):\n",
        "    def __init__(self, data, binary_encoded_labels=None, transform=None):\n",
        "        self.image_paths = data\n",
        "        self.binary_labels = binary_encoded_labels\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.binary_labels is not None:\n",
        "            single_binary_labels = self.binary_labels[idx]\n",
        "            return image, single_binary_labels, self.image_paths[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1678492913393
        },
        "tags": []
      },
      "id": "0c8d288d-72e7-43b0-8a7d-10c76bbbcbbd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create binary_encoded_labels\n",
        "\n",
        "\n",
        "binary_encoded_labels is a list that will contain binary-encoded labels for all the examples in the dataset. Each binary-encoded label is a list of 1s and 0s representing the presence or absence of each unique sub-descriptor in the label."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "0bf4d8ee-0abd-4e90-89e6-50c05bb44981"
    },
    {
      "cell_type": "code",
      "source": [
        "binary_encoded_labels = []\n",
        "# print('true: Am9(â™­5)')\n",
        "for label in dataset.values():\n",
        "    single_label_subdescriptor_dict = get_subdescriptor_dict(label)\n",
        "    binary_encoding_sublabel = []\n",
        "    # print('true:', label)\n",
        "    for subdescriptor, possibilities in possible_subdescriptors_dict.items():\n",
        "        if subdescriptor in single_label_subdescriptor_dict:\n",
        "            current_descriptor_possibilities = possible_subdescriptors_dict[subdescriptor]\n",
        "            # E = [int(single_label_subdescriptor_dict[subdescriptor] == subdescriptor_value) for subdescriptor_value in list_of_current_subdescriptors]\n",
        "            E = []\n",
        "            for subdescriptor_value in current_descriptor_possibilities:\n",
        "                # print('subdescriptor_value', subdescriptor_value)\n",
        "                # if subdescriptor in [\"alternations\"]:\n",
        "                    # if label == \"Am9(â™­5)\":\n",
        "                    #     print('single_label_subdescriptor_dict[subdescriptor]', single_label_subdescriptor_dict[subdescriptor])\n",
        "                    #     print('single_label_subdescriptor_dict[subdescriptor]', type(single_label_subdescriptor_dict[subdescriptor]))\n",
        "                    #     print('subdescriptor_value', subdescriptor_value)\n",
        "                    #     print('subdescriptor_value', type(subdescriptor_value))\n",
        "                    #     print(single_label_subdescriptor_dict[subdescriptor] == subdescriptor_value, '!!')\n",
        "                    #     print('\\n')\n",
        "                unique_subdescriptor_value = single_label_subdescriptor_dict[subdescriptor]\n",
        "                if type(unique_subdescriptor_value) == list:\n",
        "                    unique_subdescriptor_value = listToString(unique_subdescriptor_value)\n",
        "                if type(unique_subdescriptor_value) == bool:\n",
        "                    unique_subdescriptor_value = str(unique_subdescriptor_value)\n",
        "                E.append(int(unique_subdescriptor_value == subdescriptor_value))\n",
        " \n",
        "\n",
        "            binary_encoding_sublabel.extend(E)\n",
        "        else:\n",
        "            binary_encoding_sublabel.extend([0] * len(possible_subdescriptors_dict[subdescriptor]))\n",
        "    \n",
        "        # print('current_subdescriptors', current_descriptor_possibilities)\n",
        "        # print('subdescriptors_encoded', E)\n",
        "        # print('\\n')\n",
        "    binary_encoded_labels.append(binary_encoding_sublabel)\n",
        "    # print('\\n')\n"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1678492913580
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      },
      "id": "193339b4-10af-46c9-95fc-fbee0ab58d0c"
    },
    {
      "cell_type": "code",
      "source": [
        "# print(binary_encoded_labels[0])\n",
        "# print(binary_encoding_to_subdescriptor( torch.tensor(binary_encoded_labels[0])) )\n",
        "# print( [ json.dumps( binary_encoding_to_subdescriptor(torch.tensor(binary_encoded_label)), ensure_ascii=False) + '\\n \\n' for binary_encoded_label in binary_encoded_labels][0:3] )\n",
        "binary_encoded_labels_to_subdescriptors_dict = [  binary_encoding_to_subdescriptor(torch.tensor(binary_encoded_label)) for binary_encoded_label in binary_encoded_labels]"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1678492913758
        }
      },
      "id": "cbcc1e8b-f7ab-42d6-a573-ae3af7999298"
    },
    {
      "cell_type": "code",
      "source": [
        "data_labels = [*dataset.values()]\n",
        "for i, x in enumerate(binary_encoded_labels_to_subdescriptors_dict[0:10]):\n",
        "    print(data_labels[i])\n",
        "    print(pretty(x), '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "A7(#5)\n{'root': 'A',\n 'root_accidental': 'â™®',\n 'chord_type': 'dominant7',\n 'slash_note': 'N/A',\n 'alternations': \"['#5']\",\n 'diminished_substring': 'False',\n 'major_substring': 'False',\n 'minor_substring': 'False',\n 'dominant': 'True',\n 'dominant_type': '7',\n 'sus4_substring': 'False',\n 'addNote_accidental': 'N/A',\n 'addNote_degree': 'N/A'} \n\nA7add6\n{'root': 'A',\n 'root_accidental': 'â™®',\n 'chord_type': 'dominant7',\n 'slash_note': 'N/A',\n 'alternations': '[]',\n 'diminished_substring': 'False',\n 'major_substring': 'False',\n 'minor_substring': 'False',\n 'dominant': 'True',\n 'dominant_type': '7',\n 'sus4_substring': 'False',\n 'addNote_accidental': 'N/A',\n 'addNote_degree': '6'} \n\nAâ™­6\n{'root': 'A',\n 'root_accidental': 'â™­',\n 'chord_type': '6',\n 'slash_note': 'N/A',\n 'alternations': '[]',\n 'diminished_substring': 'False',\n 'major_substring': 'False',\n 'minor_substring': 'False',\n 'dominant': 'False',\n 'dominant_type': 'N/A',\n 'sus4_substring': 'False',\n 'addNote_accidental': 'N/A',\n 'addNote_degree': 'N/A'} \n\nAâ™­Maj7\n{'root': 'A',\n 'root_accidental': 'â™­',\n 'chord_type': 'maj7',\n 'slash_note': 'N/A',\n 'alternations': '[]',\n 'diminished_substring': 'False',\n 'major_substring': 'True',\n 'minor_substring': 'False',\n 'dominant': 'False',\n 'dominant_type': 'N/A',\n 'sus4_substring': 'False',\n 'addNote_accidental': 'N/A',\n 'addNote_degree': 'N/A'} \n\nBâ™­13\n{'root': 'B',\n 'root_accidental': 'â™­',\n 'chord_type': 'dominant13',\n 'slash_note': 'N/A',\n 'alternations': '[]',\n 'diminished_substring': 'False',\n 'major_substring': 'False',\n 'minor_substring': 'False',\n 'dominant': 'True',\n 'dominant_type': '13',\n 'sus4_substring': 'False',\n 'addNote_accidental': 'N/A',\n 'addNote_degree': 'N/A'} \n\nBâ™­13\n{'root': 'B',\n 'root_accidental': 'â™­',\n 'chord_type': 'dominant13',\n 'slash_note': 'N/A',\n 'alternations': '[]',\n 'diminished_substring': 'False',\n 'major_substring': 'False',\n 'minor_substring': 'False',\n 'dominant': 'True',\n 'dominant_type': '13',\n 'sus4_substring': 'False',\n 'addNote_accidental': 'N/A',\n 'addNote_degree': 'N/A'} \n\nBâ™­13\n{'root': 'B',\n 'root_accidental': 'â™­',\n 'chord_type': 'dominant13',\n 'slash_note': 'N/A',\n 'alternations': '[]',\n 'diminished_substring': 'False',\n 'major_substring': 'False',\n 'minor_substring': 'False',\n 'dominant': 'True',\n 'dominant_type': '13',\n 'sus4_substring': 'False',\n 'addNote_accidental': 'N/A',\n 'addNote_degree': 'N/A'} \n\nC7(#9)\n{'root': 'C',\n 'root_accidental': 'â™®',\n 'chord_type': 'dominant7',\n 'slash_note': 'N/A',\n 'alternations': \"['#9']\",\n 'diminished_substring': 'False',\n 'major_substring': 'False',\n 'minor_substring': 'False',\n 'dominant': 'True',\n 'dominant_type': '7',\n 'sus4_substring': 'False',\n 'addNote_accidental': 'N/A',\n 'addNote_degree': 'N/A'} \n\nC9\n{'root': 'C',\n 'root_accidental': 'â™®',\n 'chord_type': 'dominant9',\n 'slash_note': 'N/A',\n 'alternations': '[]',\n 'diminished_substring': 'False',\n 'major_substring': 'False',\n 'minor_substring': 'False',\n 'dominant': 'True',\n 'dominant_type': '9',\n 'sus4_substring': 'False',\n 'addNote_accidental': 'N/A',\n 'addNote_degree': 'N/A'} \n\nC9\n{'root': 'C',\n 'root_accidental': 'â™®',\n 'chord_type': 'dominant9',\n 'slash_note': 'N/A',\n 'alternations': '[]',\n 'diminished_substring': 'False',\n 'major_substring': 'False',\n 'minor_substring': 'False',\n 'dominant': 'True',\n 'dominant_type': '9',\n 'sus4_substring': 'False',\n 'addNote_accidental': 'N/A',\n 'addNote_degree': 'N/A'} \n\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1678492913944
        }
      },
      "id": "13cd500a-8ab3-4fa8-8bf6-5c1d4d4779e3"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "40fdf7c3-c487-4674-9f03-368a3b7e51f3"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "6c147a29-84ee-4112-9cf7-6765806a73a4"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "9323687e-2e20-40bc-b4f7-5c65a0b049a1"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "f13a2600-1516-4911-aaae-5e575639d122"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "2cabbd52-5152-47bf-928f-542eaa1c44d0"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "0f8c76ab-4646-4a5a-b366-9ea3b116bc9e"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "8449a52c-fdf9-49eb-9a09-c5ff044f38ef"
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(binary_encoded_labels))\n",
        "print(len(binary_encoded_labels[0]))\n",
        "print(binary_encoded_labels[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "502\n73\n[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1678492914146
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "dcbc78c7-5f1c-448c-a886-2bc42b7e2eb8"
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths_stack = []\n",
        "for image_path, label in dataset.items():\n",
        "        image_paths_stack.append(image_path)"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1678492914361
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "b8810494-27e9-414e-8517-9a3ecd1bc601"
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(binary_encoded_labels))\n",
        "print(len(binary_encoded_labels[0]))\n",
        "print(len(image_paths_stack))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "502\n73\n502\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1678492914610
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "bc023ac9-d35a-41f7-87cd-aaaf7e5aa480"
    },
    {
      "cell_type": "code",
      "source": [
        "binary_encoded_labels_tensor = torch.tensor(binary_encoded_labels)"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1678492914813
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "3ceccc55-6310-4d09-a90d-8c511191660b"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(image_paths_stack, binary_encoded_labels_tensor, test_size=0.4, random_state=42)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1678492914999
        },
        "tags": []
      },
      "id": "b0b80792-76de-4d15-a937-3554af2c0f79"
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    # transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1678492915184
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "544b2663-3097-425a-981d-79002d9f6230"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define PreparedDataset Objects"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "fd1464be-8484-4314-9c03-bb62f2b733b3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the train and test datasets\n",
        "train_data = PreparedDataset(X_train, y_train, transform=transform_train)\n",
        "test_data = PreparedDataset(X_test, y_test, transform=transform_test)"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1678492915378
        },
        "tags": []
      },
      "id": "b9d9e88a-a532-40a7-aade-e5b8f1749d00"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Resnet Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      },
      "id": "fb0a80fa-a2df-42ac-a4cc-0f9956ab84c4"
    },
    {
      "cell_type": "code",
      "source": [
        "# %%script echo skipping\n",
        "BINARY_ENCODING_LENGTH = len(binary_encoded_labels[0])                      ## relates to all 73 unique possible subdescriptor values\n",
        "\n",
        "# Initialize the model\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=BINARY_ENCODING_LENGTH)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/jupyter_env/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/anaconda/envs/jupyter_env/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1678492915581
        },
        "tags": []
      },
      "id": "5d4f4ce6-ee67-48ac-86c1-afbfea0f1b80"
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 64\n",
        "# batch_size = 32\n",
        "batch_size = 16"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1678492915783
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "184235ca-8162-40a0-9dcb-f647fef7e3be"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Data Loaders"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "3e5b8d44-5a53-407e-8a47-5e6379ed8f09"
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, drop_last=True)"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1678492915945
        },
        "tags": []
      },
      "id": "02c7dbc5-7c1d-4625-8d80-d5e0ff46165f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "99d42ba3-ee82-4304-a20f-abcbbb47747e"
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=0.001 \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1678492916129
        }
      },
      "id": "e99dec5b-ac6a-4d8b-a602-ebd691036470"
    },
    {
      "cell_type": "code",
      "source": [
        "# %%script echo skipped\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch:', epoch)\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (images_t, labels_t, image_filepaths) in enumerate(train_loader):                ## labels_t is list of binary encoding tensors\n",
        "        print(f\"Batch #{i}\")\n",
        "\n",
        "        images_t = images_t.to(device)\n",
        "        labels_t = labels_t.to(device)\n",
        "        \n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass, backward pass, and optimize\n",
        "        logits = model(images_t)\n",
        "\n",
        "        # Apply sigmoid activation to logits to convert to probabilities\n",
        "        probabilities = torch.sigmoid(logits)\n",
        "\n",
        "        # Convert probabilities to binary predictions using a threshold of 0.5\n",
        "        predictions = (probabilities >= 0.5).long()\n",
        "\n",
        "        labels_t = labels_t.float()\n",
        "\n",
        "        loss = criterion(logits, labels_t)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print statistics\n",
        "        running_loss += loss.item()\n",
        "        if (i + 1) % 5 == 0:\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}: loss {running_loss / 5:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "torch.save(model.state_dict(), 'leadsheet-ocr--binary_encoding-V1.pth')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch: 0\nBatch #0\nBatch #1\nBatch #2\nBatch #3\nBatch #4\nEpoch 1, Batch 5: loss 0.358\nBatch #5\nBatch #6\nBatch #7\nBatch #8\nBatch #9\nEpoch 1, Batch 10: loss 0.145\nBatch #10\nBatch #11\nBatch #12\nBatch #13\nBatch #14\nEpoch 1, Batch 15: loss 0.121\nBatch #15\nBatch #16\nBatch #17\nEpoch: 1\nBatch #0\nBatch #1\nBatch #2\nBatch #3\nBatch #4\nEpoch 2, Batch 5: loss 0.081\nBatch #5\nBatch #6\nBatch #7\nBatch #8\nBatch #9\nEpoch 2, Batch 10: loss 0.080\nBatch #10\nBatch #11\nBatch #12\nBatch #13\nBatch #14\nEpoch 2, Batch 15: loss 0.087\nBatch #15\nBatch #16\nBatch #17\nEpoch: 2\nBatch #0\nBatch #1\nBatch #2\nBatch #3\nBatch #4\nEpoch 3, Batch 5: loss 0.070\nBatch #5\nBatch #6\nBatch #7\nBatch #8\nBatch #9\nEpoch 3, Batch 10: loss 0.067\nBatch #10\nBatch #11\nBatch #12\nBatch #13\nBatch #14\nEpoch 3, Batch 15: loss 0.052\nBatch #15\nBatch #16\nBatch #17\nEpoch: 3\nBatch #0\nBatch #1\nBatch #2\nBatch #3\nBatch #4\nEpoch 4, Batch 5: loss 0.049\nBatch #5\nBatch #6\nBatch #7\nBatch #8\nBatch #9\nEpoch 4, Batch 10: loss 0.068\nBatch #10\nBatch #11\nBatch #12\nBatch #13\nBatch #14\nEpoch 4, Batch 15: loss 0.058\nBatch #15\nBatch #16\nBatch #17\nEpoch: 4\nBatch #0\nBatch #1\nBatch #2\nBatch #3\nBatch #4\nEpoch 5, Batch 5: loss 0.042\nBatch #5\nBatch #6\nBatch #7\nBatch #8\nBatch #9\nEpoch 5, Batch 10: loss 0.044\nBatch #10\nBatch #11\nBatch #12\nBatch #13\nBatch #14\nEpoch 5, Batch 15: loss 0.041\nBatch #15\nBatch #16\nBatch #17\nEpoch: 5\nBatch #0\nBatch #1\nBatch #2\nBatch #3\nBatch #4\nEpoch 6, Batch 5: loss 0.042\nBatch #5\nBatch #6\nBatch #7\nBatch #8\nBatch #9\nEpoch 6, Batch 10: loss 0.029\nBatch #10\nBatch #11\nBatch #12\nBatch #13\nBatch #14\nEpoch 6, Batch 15: loss 0.039\nBatch #15\nBatch #16\nBatch #17\nEpoch: 6\nBatch #0\nBatch #1\nBatch #2\nBatch #3\nBatch #4\nEpoch 7, Batch 5: loss 0.025\nBatch #5\nBatch #6\nBatch #7\nBatch #8\nBatch #9\nEpoch 7, Batch 10: loss 0.031\nBatch #10\nBatch #11\nBatch #12\nBatch #13\nBatch #14\nEpoch 7, Batch 15: loss 0.026\nBatch #15\nBatch #16\nBatch #17\nEpoch: 7\nBatch #0\nBatch #1\nBatch #2\nBatch #3\nBatch #4\nEpoch 8, Batch 5: loss 0.020\nBatch #5\nBatch #6\nBatch #7\nBatch #8\nBatch #9\nEpoch 8, Batch 10: loss 0.026\nBatch #10\nBatch #11\nBatch #12\nBatch #13\nBatch #14\nEpoch 8, Batch 15: loss 0.027\nBatch #15\nBatch #16\nBatch #17\nEpoch: 8\nBatch #0\nBatch #1\nBatch #2\nBatch #3\nBatch #4\nEpoch 9, Batch 5: loss 0.025\nBatch #5\nBatch #6\nBatch #7\nBatch #8\nBatch #9\nEpoch 9, Batch 10: loss 0.025\nBatch #10\nBatch #11\nBatch #12\nBatch #13\nBatch #14\nEpoch 9, Batch 15: loss 0.022\nBatch #15\nBatch #16\nBatch #17\nEpoch: 9\nBatch #0\nBatch #1\nBatch #2\nBatch #3\nBatch #4\nEpoch 10, Batch 5: loss 0.016\nBatch #5\nBatch #6\nBatch #7\nBatch #8\nBatch #9\nEpoch 10, Batch 10: loss 0.022\nBatch #10\nBatch #11\nBatch #12\nBatch #13\nBatch #14\nEpoch 10, Batch 15: loss 0.015\nBatch #15\nBatch #16\nBatch #17\n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1678493743147
        },
        "tags": []
      },
      "id": "dff396e0-608a-40ca-9644-fdf092a5b32d"
    },
    {
      "cell_type": "code",
      "source": [
        "# %%script echo skipping\n",
        "# model.load_state_dict(torch.load('leadsheet-ocr--binary_encoding-V1.pth'))"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1678493743380
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        }
      },
      "id": "c694b31d-a1fe-4f7a-9976-3ca21c68dd26"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "55231ef1-0676-448b-a572-cee7c8354443"
    },
    {
      "cell_type": "code",
      "source": [
        "# %%script echo skipping\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "PRINT_PREDICTIONS = True\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Create a list to store the true labels and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "predicted_filepaths = []\n",
        "\n",
        "prediction_accuracies = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (images_t, labels_t, image_filepaths) in enumerate(test_loader):\n",
        "        print(f\"Batch #{i}\")\n",
        "\n",
        "        # # Move the inputs and labels to the device\n",
        "        images_t = images_t.to(device)\n",
        "        labels_t = labels_t.to(device)\n",
        "\n",
        "        # Forward pass through the model to get logits\n",
        "        logits = model(images_t)\n",
        "\n",
        "        # Apply sigmoid activation to logits to convert to probabilities\n",
        "        probabilities = torch.sigmoid(logits)\n",
        "\n",
        "        # Convert probabilities to binary predictions using a threshold of 0.5\n",
        "        predictions = (probabilities >= 0.5).long()\n",
        "\n",
        "        # if PRINT_PREDICTIONS and i in [0,2]:\n",
        "        #     for i, zipped in enumerate(zip(labels_t, predictions, image_filepaths)):\n",
        "        #         # print('zipped!', zipped)\n",
        "        #         print(zipped[0])\n",
        "        #         # print(f\"-- true chord[{i}]:\",  binary_encoding_to_subdescriptor(zipped[0]))\n",
        "        #         true_labels.append(zipped[0])\n",
        "        #         # print(f\"-- pred chord[{i}]:\",  binary_encoding_to_subdescriptor(zipped[1]))\n",
        "        #         predicted_labels.append(zipped[1])\n",
        "        #         # print(f\"True filepath: {zipped[2]}\")\n",
        "        #         predicted_filepaths.append(zipped[2])\n",
        "        #         # print('\\n')\n",
        "\n",
        "        true_labels.extend(labels_t)\n",
        "        predicted_labels.extend(predictions)\n",
        "        predicted_filepaths.extend(image_filepaths)\n",
        "\n",
        "        # mask = labels_t.float().eq(1)\n",
        "        # correct = (predictions * labels_t).masked_select(mask).sum().item()\n",
        "            \n",
        "        # total = labels_t.sum().item()\n",
        "        # accuracy = correct / total * 100\n",
        "\n",
        "        # print(f\"-- accuracy {accuracy}% \\n\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Batch #6\nBatch #0\nBatch #1\nBatch #2\nBatch #3\nBatch #4\nBatch #5\nBatch #6\nBatch #7\nBatch #8\nBatch #9\nBatch #10\nBatch #11\n"
        }
      ],
      "execution_count": 58,
      "metadata": {
        "gather": {
          "logged": 1678495868489
        },
        "jupyter": {
          "source_hidden": false
        }
      },
      "id": "4054aab0-be3c-4afc-9a91-0c1ea36deec8"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1678495868846
        }
      },
      "id": "23ac66fb-d1ea-4a0a-b149-32616cb9b926"
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc = []\n",
        "for i in range(len(true_labels)):\n",
        "    mask = true_labels[i].float().eq(1)\n",
        "    correct = (predicted_labels[i] * true_labels[i]).masked_select(mask).sum().item()\n",
        "        \n",
        "    total = true_labels[i].sum().item()\n",
        "    accuracy = correct / total * 100\n",
        "\n",
        "    # print(predicted_filepaths[i])\n",
        "    # print(f\"-- accuracy {accuracy}% \\n\")\n",
        "    val_acc.append(accuracy)"
      ],
      "outputs": [],
      "execution_count": 46,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1678495280070
        }
      },
      "id": "a2965fe9-9c96-4d82-8392-56af1434f9a7"
    },
    {
      "cell_type": "code",
      "source": [
        "print('--------------- Accuracy < 90  ---------------')\n",
        "for i, accuracy in enumerate(val_acc):\n",
        "    if accuracy < 90:\n",
        "        print(filepathToChord(predicted_filepaths[i]))\n",
        "        print(f\"-- accuracy {accuracy}% \\n\")\n",
        "\n",
        "print('\\n')\n",
        "print('--------------- 90 < Accuracy < 98  ---------------')\n",
        "for i, accuracy in enumerate(val_acc):\n",
        "    if accuracy > 90 and accuracy < 98:\n",
        "        print(filepathToChord(predicted_filepaths[i]))\n",
        "        print(f\"-- accuracy {accuracy}% \\n\")\n",
        "\n",
        "print('\\n')\n",
        "print('--------------- Accuracy > 98 ---------------')\n",
        "for i, accuracy in enumerate(val_acc):\n",
        "    if accuracy > 98:\n",
        "        print(filepathToChord(predicted_filepaths[i]))\n",
        "        print(f\"-- accuracy {accuracy}% \\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "--------------- Accuracy < 90  ---------------\nG13\n-- accuracy 76.92307692307693% \n\nEâ™­madd9\n-- accuracy 84.61538461538461% \n\nA13(#11)\n-- accuracy 69.23076923076923% \n\nF7(#11)\n-- accuracy 84.61538461538461% \n\nEâ™­o7\n-- accuracy 84.61538461538461% \n\nD13sus4\n-- accuracy 84.61538461538461% \n\nF13sus4\n-- accuracy 84.61538461538461% \n\nF6\n-- accuracy 84.61538461538461% \n\nAo7(â™­13)\n-- accuracy 69.23076923076923% \n\nBâ™­9sus4\n-- accuracy 84.61538461538461% \n\n\n\n--------------- 90 < Accuracy < 98  ---------------\nGâ™­7sus4\n-- accuracy 92.3076923076923% \n\nAâ™­Maj7(#5)\n-- accuracy 92.3076923076923% \n\nAm9(â™­5)\n-- accuracy 92.3076923076923% \n\nF#69\n-- accuracy 92.3076923076923% \n\nBâ™­m6\n-- accuracy 92.3076923076923% \n\nAâ™­6\n-- accuracy 92.3076923076923% \n\nC7(#9)\n-- accuracy 92.3076923076923% \n\nEâ™­7(#11)\n-- accuracy 92.3076923076923% \n\nA7(#5)\n-- accuracy 92.3076923076923% \n\nEMaj7(â™­5)\n-- accuracy 92.3076923076923% \n\nFm11\n-- accuracy 92.3076923076923% \n\nBo7\n-- accuracy 92.3076923076923% \n\nC#7(#9)\n-- accuracy 92.3076923076923% \n\nD#m7(â™­5)\n-- accuracy 92.3076923076923% \n\nBâ™­7(#5)\n-- accuracy 92.3076923076923% \n\nG#m9\n-- accuracy 92.3076923076923% \n\nG#m7(â™­5)\n-- accuracy 92.3076923076923% \n\nDm9\n-- accuracy 92.3076923076923% \n\nEMaj7(â™­5)\n-- accuracy 92.3076923076923% \n\nDm7(â™­5)\n-- accuracy 92.3076923076923% \n\nG#m9(#5)\n-- accuracy 92.3076923076923% \n\nDm7(â™­5)\n-- accuracy 92.3076923076923% \n\nF6\n-- accuracy 92.3076923076923% \n\nG9\n-- accuracy 92.3076923076923% \n\nDm9\n-- accuracy 92.3076923076923% \n\nDâ™­7(#11)\n-- accuracy 92.3076923076923% \n\nF7(#11)\n-- accuracy 92.3076923076923% \n\nDm9\n-- accuracy 92.3076923076923% \n\nFm6\n-- accuracy 92.3076923076923% \n\nC#7(â™­9#11)\n-- accuracy 92.3076923076923% \n\nC#7(#5#9)\n-- accuracy 92.3076923076923% \n\nG13\n-- accuracy 92.3076923076923% \n\nB9sus4\n-- accuracy 92.3076923076923% \n\nC#m9\n-- accuracy 92.3076923076923% \n\nC7(#9)\n-- accuracy 92.3076923076923% \n\nC#m9\n-- accuracy 92.3076923076923% \n\nG#m9(#5)\n-- accuracy 92.3076923076923% \n\nF6\n-- accuracy 92.3076923076923% \n\nC7#5\n-- accuracy 92.3076923076923% \n\nBâ™­Maj7(#5)\n-- accuracy 92.3076923076923% \n\nB9sus4\n-- accuracy 92.3076923076923% \n\nF7(#5)\n-- accuracy 92.3076923076923% \n\n\n\n--------------- Accuracy > 98 ---------------\nF#m7\n-- accuracy 100.0% \n\nAm7\n-- accuracy 100.0% \n\nE7\n-- accuracy 100.0% \n\nEm7\n-- accuracy 100.0% \n\nE9sus4\n-- accuracy 100.0% \n\nBm7\n-- accuracy 100.0% \n\nEâ™­m9\n-- accuracy 100.0% \n\nAm7\n-- accuracy 100.0% \n\nBm7\n-- accuracy 100.0% \n\nC9\n-- accuracy 100.0% \n\nGm7\n-- accuracy 100.0% \n\nBâ™­7sus4\n-- accuracy 100.0% \n\nBm7\n-- accuracy 100.0% \n\nEâ™­m9\n-- accuracy 100.0% \n\nFm7\n-- accuracy 100.0% \n\nEâ™­Maj7\n-- accuracy 100.0% \n\nG7\n-- accuracy 100.0% \n\nGm7\n-- accuracy 100.0% \n\nAm7\n-- accuracy 100.0% \n\nEMaj9\n-- accuracy 100.0% \n\nAm9\n-- accuracy 100.0% \n\nFm6\n-- accuracy 100.0% \n\nE7(â™­9)\n-- accuracy 100.0% \n\nC7\n-- accuracy 100.0% \n\nF#m7add4\n-- accuracy 100.0% \n\nE7(â™­9)\n-- accuracy 100.0% \n\nG#7(#5)\n-- accuracy 100.0% \n\nAm7\n-- accuracy 100.0% \n\nBâ™­13\n-- accuracy 100.0% \n\nFMaj7\n-- accuracy 100.0% \n\nDâ™­7\n-- accuracy 100.0% \n\nD9\n-- accuracy 100.0% \n\nCm7(â™­5)\n-- accuracy 100.0% \n\nAâ™­7sus4\n-- accuracy 100.0% \n\nAm7\n-- accuracy 100.0% \n\nCm7\n-- accuracy 100.0% \n\nDâ™­7\n-- accuracy 100.0% \n\nAm7\n-- accuracy 100.0% \n\nDMaj7\n-- accuracy 100.0% \n\nBm7\n-- accuracy 100.0% \n\nBâ™­13\n-- accuracy 100.0% \n\nGm7\n-- accuracy 100.0% \n\nD7\n-- accuracy 100.0% \n\nEm7\n-- accuracy 100.0% \n\nEâ™­9sus4\n-- accuracy 100.0% \n\nAm7\n-- accuracy 100.0% \n\nFm7\n-- accuracy 100.0% \n\nB7(â™­9)\n-- accuracy 100.0% \n\nC#Maj7\n-- accuracy 100.0% \n\nC#7(â™­9)\n-- accuracy 100.0% \n\nDâ™­7sus4\n-- accuracy 100.0% \n\nF#m7\n-- accuracy 100.0% \n\nEâ™­m9\n-- accuracy 100.0% \n\nEâ™­Maj7\n-- accuracy 100.0% \n\nBm7\n-- accuracy 100.0% \n\nAm7\n-- accuracy 100.0% \n\nE9sus4\n-- accuracy 100.0% \n\nBâ™­7sus4\n-- accuracy 100.0% \n\nDMaj7\n-- accuracy 100.0% \n\nA7\n-- accuracy 100.0% \n\nE9\n-- accuracy 100.0% \n\nBm7(â™­5)\n-- accuracy 100.0% \n\nBâ™­7(#5)\n-- accuracy 100.0% \n\nFm7\n-- accuracy 100.0% \n\nC9\n-- accuracy 100.0% \n\nDm7\n-- accuracy 100.0% \n\nBâ™­m7\n-- accuracy 100.0% \n\nF#m6\n-- accuracy 100.0% \n\nE9(â™­5)\n-- accuracy 100.0% \n\nAâ™­13\n-- accuracy 100.0% \n\nGm7(â™­5)\n-- accuracy 100.0% \n\nFm7\n-- accuracy 100.0% \n\nEâ™­Maj7\n-- accuracy 100.0% \n\nBm7\n-- accuracy 100.0% \n\nAm7\n-- accuracy 100.0% \n\nGm7(â™­5)\n-- accuracy 100.0% \n\nC#m7\n-- accuracy 100.0% \n\nD7(â™­9)\n-- accuracy 100.0% \n\nEMaj7\n-- accuracy 100.0% \n\nFm7\n-- accuracy 100.0% \n\nBâ™­7\n-- accuracy 100.0% \n\nAMaj7\n-- accuracy 100.0% \n\nEâ™­Maj7\n-- accuracy 100.0% \n\nBâ™­7sus4\n-- accuracy 100.0% \n\nBm7\n-- accuracy 100.0% \n\nCm6\n-- accuracy 100.0% \n\nC7\n-- accuracy 100.0% \n\nFm9\n-- accuracy 100.0% \n\nAâ™­Maj7\n-- accuracy 100.0% \n\nC#m7\n-- accuracy 100.0% \n\nB13\n-- accuracy 100.0% \n\nGm7\n-- accuracy 100.0% \n\nDm7\n-- accuracy 100.0% \n\nB13\n-- accuracy 100.0% \n\nCMaj7\n-- accuracy 100.0% \n\nFm7\n-- accuracy 100.0% \n\nE7\n-- accuracy 100.0% \n\nGMaj7\n-- accuracy 100.0% \n\nBm7\n-- accuracy 100.0% \n\nAm7\n-- accuracy 100.0% \n\nFm7\n-- accuracy 100.0% \n\nGm7\n-- accuracy 100.0% \n\nAm7\n-- accuracy 100.0% \n\nAâ™­13\n-- accuracy 100.0% \n\nCMaj7\n-- accuracy 100.0% \n\nEâ™­7sus4\n-- accuracy 100.0% \n\nFm9\n-- accuracy 100.0% \n\nFMaj7\n-- accuracy 100.0% \n\nBâ™­13\n-- accuracy 100.0% \n\nBâ™­13\n-- accuracy 100.0% \n\nD9\n-- accuracy 100.0% \n\nDâ™­9\n-- accuracy 100.0% \n\nAâ™­Maj7\n-- accuracy 100.0% \n\nEâ™­Maj7\n-- accuracy 100.0% \n\nE9sus4\n-- accuracy 100.0% \n\nEâ™­m9\n-- accuracy 100.0% \n\nBâ™­13\n-- accuracy 100.0% \n\nFMaj7\n-- accuracy 100.0% \n\nDMaj7\n-- accuracy 100.0% \n\nF#m7add4\n-- accuracy 100.0% \n\nAâ™­Maj7\n-- accuracy 100.0% \n\nEâ™­Maj7\n-- accuracy 100.0% \n\nE9\n-- accuracy 100.0% \n\nG7add6\n-- accuracy 100.0% \n\nFm9\n-- accuracy 100.0% \n\nE9\n-- accuracy 100.0% \n\nC#Maj7\n-- accuracy 100.0% \n\nF#m6\n-- accuracy 100.0% \n\nGm7\n-- accuracy 100.0% \n\nE7(â™­9)\n-- accuracy 100.0% \n\nDMaj7\n-- accuracy 100.0% \n\nD7\n-- accuracy 100.0% \n\nBm7\n-- accuracy 100.0% \n\nD7(â™­9)\n-- accuracy 100.0% \n\nCMaj7\n-- accuracy 100.0% \n\nDMaj7\n-- accuracy 100.0% \n\nFMaj7\n-- accuracy 100.0% \n\nC#m7\n-- accuracy 100.0% \n\nAm7\n-- accuracy 100.0% \n\nB13\n-- accuracy 100.0% \n\n"
        }
      ],
      "execution_count": 76,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1678496358440
        }
      },
      "id": "eb85b053-498a-4e3d-b628-2557cd6aa0ed"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the Testing Accuracy"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "8fe1084c-5466-48f6-ad37-e67bf997d9f1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "e05ba4b7-d8d8-4be9-ab0f-64e6474192d1"
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo skipped\n",
        "# plt.plot(train_acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.ylim([90, 100])\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "skipped\n"
        }
      ],
      "execution_count": 48,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1678495291139
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      },
      "id": "b8d189a4-83fa-4089-8df3-679fec18e2b7"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "cfee3658-3091-4094-a58d-a7cc3ff21bf6"
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}